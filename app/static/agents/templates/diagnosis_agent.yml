name: diagnosis_agent
description: >
  PyTune Diagnosis Agent â€” prepares the user to start the piano acoustic diagnosis using the microphone and optionally AirPods.

triggers:
  - event: page_visit
    condition: current_page in ["/diagnosis"]

start:
  say: |
    ğŸ™ï¸ To start the PyTune Diagnosis you will need:
    - one or more MICROPHONES
    - (optional) a connected headset or AirPods to receive audio cues.

    â±ï¸ The full process takes about 2 minutes:
    - microphone calibration and A4 reference note
    - guided chromatic scale
    - a few long notes at the low and high ends
  actions:
    - suggest_action: "Continue"
      trigger_event: continue_intro
    - suggest_action: "â„¹ï¸ What is PyTune Diagnosis?"
      route_to: "/diagnosis/about"

conversation:
  - if: event == "continue_intro"
    say: "ğŸ¤ Please connect one or more microphones to continue."
    actions:
      - suggest_action: "Connect microphones"
        trigger_event: connect_micro

  - elif: event == "connect_micro"
    say: "ğŸ” Checking WebSocket connection and latency..."
    actions:
      - suggest_action: "Test connection"
        trigger_event: test_ws

  - elif: event == "latency_ok" and diagnosis.ws_connected == True and diagnosis.mic_ready == True and diagnosis.latency_ms < 100
    say: "ğŸ“¶ Latency acceptable ({{ diagnosis.latency_ms }} ms). Would you like to use AirPods or a headset for audio instructions?"
    actions:
      - suggest_action: "ğŸ§ Connect AirPods"
        trigger_event: connect_airpods
      - suggest_action: "ğŸš€ Continue without headset"
        trigger_event: continue_without_headset

  - elif: event == "connect_airpods"
    say: |
      ğŸ§ Searching for available Bluetooth audio output devices...
      Once connected, PyTune will speak each instruction directly into your headset.
    actions:
      - suggest_action: "Scan and connect"
        trigger_event: scan_airpods
      - suggest_action: "Skip headset"
        trigger_event: continue_without_headset

  - elif: event == "scan_airpods"
    say: "ğŸ”Š Scanning for AirPods..."
    actions:
      - suggest_action: "Confirm AirPods setup"
        trigger_event: airpods_confirmed
      - suggest_action: "Cancel"
        trigger_event: airpods_cancelled

  - elif: event == "airpods_confirmed"
    say: "âœ… AirPods connected successfully! Youâ€™ll now hear voice instructions through your headset."
    actions:
      - suggest_action: "â–¶ï¸ Start Diagnosis"
        trigger_event: start_diagnosis

  - elif: event == "airpods_cancelled"
    say: "â AirPods setup cancelled. You can still continue without them."
    actions:
      - suggest_action: "Continue without headset"
        trigger_event: continue_without_headset

  - elif: event == "continue_without_headset"
    say: "ğŸ§ You chose to continue without AirPods. You can still hear voice prompts through your computer speakers."
    actions:
      - suggest_action: "â–¶ï¸ Start Diagnosis"
        trigger_event: start_diagnosis

  - elif: event == "latency_ok" and (diagnosis.ws_connected != True or diagnosis.mic_ready != True)
    say: "âš ï¸ Microphone or WebSocket not ready. Please retry."

  - elif: event == "latency_ok" and diagnosis.latency_ms >= 100
    say: "âš ï¸ Latency too high ({{ diagnosis.latency_ms }} ms). Please check your connection and retry."

  - elif: event == "start_diagnosis"
    say: |
      ğŸš€ Diagnosis is starting now.
      Please follow on-screen or spoken instructions.
      (e.g., â€œPlay note B1â€, â€œHold note C2â€, or tune higher/lower as indicated.)

  - else: true
    continue: true
    say: "ğŸ¤” I'm not sure what to do. Please try again."
    actions: []

metadata:
  version: "1.3"
  title: "ğŸ¹ PyTune Diagnosis Agent"
  lang: en
  allow_interruptions: false
  memory: false
  context_key: diagnosis_session

context:
  variables: {}